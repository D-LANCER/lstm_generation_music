{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "together-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thorough-sudan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0-rc0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "becoming-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "broke-sessions",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cosmetic-lindsay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 8s 1us/step\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incorrect-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "differential-extent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 386us/step - loss: 0.1125 - accuracy: 0.9654\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 383us/step - loss: 0.1047 - accuracy: 0.9689\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 386us/step - loss: 0.1047 - accuracy: 0.9683\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 399us/step - loss: 0.1005 - accuracy: 0.9695\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 378us/step - loss: 0.0971 - accuracy: 0.9702\n",
      "313/313 - 0s - loss: 0.0921 - accuracy: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09205330163240433, 0.9750000238418579]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "geographic-experiment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.4955 - accuracy: 0.8263\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.3707 - accuracy: 0.8653\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.3335 - accuracy: 0.8779\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.3117 - accuracy: 0.8857\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.2906 - accuracy: 0.8924\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2787 - accuracy: 0.8969\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2674 - accuracy: 0.9004\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 85us/sample - loss: 0.2522 - accuracy: 0.9064\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 86us/sample - loss: 0.2465 - accuracy: 0.9089\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.2354 - accuracy: 0.9114\n",
      "\n",
      "\n",
      "Training set contained 60000 images\n",
      "Testing set contained 10000 images\n",
      "Model achieved 0.88 testing accuracy\n",
      "Training and testing took 53.02 seconds\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "#from tensorflow.python.compiler.mlcompute import mlcompute\n",
    "#mlcompute.set_mlc_device(device_name='gpu')\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.python.compiler.mlcompute import mlcompute\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "mlcompute.set_mlc_device(device_name='gpu') # Available options are 'cpu', 'gpu', and 'any'.\n",
    "tf.config.run_functions_eagerly(False)\n",
    "print(tf.executing_eagerly())\n",
    "\n",
    "#download fashion mnist dataset\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_set_count = len(train_labels)\n",
    "test_set_count = len(test_labels)\n",
    "\n",
    "#setup start time\n",
    "t0 = time.time()\n",
    "\n",
    "#normalize images\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "#create ML model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "#compile ML model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#train ML model\n",
    "model.fit(train_images, train_labels, epochs=10)\n",
    "\n",
    "#evaluate ML model on test set\n",
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "\n",
    "#setup stop time\n",
    "t1 = time.time()\n",
    "total_time = t1-t0\n",
    "\n",
    "#print results\n",
    "print('\\n')\n",
    "print(f'Training set contained {train_set_count} images')\n",
    "print(f'Testing set contained {test_set_count} images')\n",
    "print(f'Model achieved {test_acc:.2f} testing accuracy')\n",
    "print(f'Training and testing took {total_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "enabling-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "silver-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "partial-signal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "digital-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "sequence_length = 4\n",
    "num_sequence = len(a) - sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "voluntary-perspective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6)\n",
      "[array([0, 1, 2, 3, 4, 5])]\n",
      "(2, 6)\n",
      "[array([0, 1, 2, 3, 4, 5]), array([1, 2, 3, 4, 5, 6])]\n",
      "(3, 6)\n",
      "[array([0, 1, 2, 3, 4, 5]), array([1, 2, 3, 4, 5, 6]), array([2, 3, 4, 5, 6, 7])]\n",
      "(4, 6)\n",
      "[array([0, 1, 2, 3, 4, 5]), array([1, 2, 3, 4, 5, 6]), array([2, 3, 4, 5, 6, 7]), array([3, 4, 5, 6, 7, 8])]\n",
      "(5, 6)\n",
      "[array([0, 1, 2, 3, 4, 5]), array([1, 2, 3, 4, 5, 6]), array([2, 3, 4, 5, 6, 7]), array([3, 4, 5, 6, 7, 8]), array([4, 5, 6, 7, 8, 9])]\n",
      "(6,)\n",
      "[array([0, 1, 2, 3, 4, 5]), array([1, 2, 3, 4, 5, 6]), array([2, 3, 4, 5, 6, 7]), array([3, 4, 5, 6, 7, 8]), array([4, 5, 6, 7, 8, 9]), array([5, 6, 7, 8, 9])]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_sequence):\n",
    "    b.append(a[i:i+num_sequence])\n",
    "    print(np.array(b).shape)\n",
    "    print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "previous-magazine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array(b)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "preliminary-amazon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 1, 2, 3, 4, 5]) array([1, 2, 3, 4, 5, 6])\n",
      " array([2, 3, 4, 5, 6, 7]) array([3, 4, 5, 6, 7, 8])\n",
      " array([4, 5, 6, 7, 8, 9]) array([5, 6, 7, 8, 9])]\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-creek",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
